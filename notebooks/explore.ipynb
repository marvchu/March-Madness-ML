{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, matthews_corrcoef, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "df_1 = pd.read_csv(r'C:\\Users\\Sweat\\OneDrive\\Desktop\\march_madness_ai\\data\\raw\\Shooting_Splits.csv')\n",
    "df_2 = pd.read_csv(r'C:\\Users\\Sweat\\OneDrive\\Desktop\\march_madness_ai\\data\\raw\\Barttorvik_Away_Neutral.csv')\n",
    "df_3 = pd.read_csv(r'C:\\Users\\Sweat\\OneDrive\\Desktop\\march_madness_ai\\data\\raw\\mmWinLoss.csv')\n",
    "df_4 = pd.read_csv(r'C:\\Users\\Sweat\\OneDrive\\Desktop\\march_madness_ai\\data\\raw\\teamID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0017f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose preferred columns\n",
    "df_3_col = [\n",
    "    'Season', 'WTeamID' , 'LTeamID'\n",
    "]\n",
    "\n",
    "df_4_col = [\n",
    "    'TeamID', 'TeamName'\n",
    "]\n",
    "\n",
    "df_splits = df_1.drop('CONF', axis=1)\n",
    "df_stats = df_2.drop('ROUND', axis=1)\n",
    "df_WL = df_3[df_3_col]\n",
    "df_ID = df_4[df_4_col]\n",
    "\n",
    "team_stats = pd.merge(df_splits, df_stats, on=['YEAR', 'TEAM'], how='inner')\n",
    "\n",
    "#Match ID to team name\n",
    "df_merged = df_WL.merge(df_ID, left_on='WTeamID', right_on='TeamID', how='left')\n",
    "df_merged = df_merged.rename(columns={'TeamName':'WTeamName'})\n",
    "\n",
    "df_merged = df_merged.merge(df_ID, left_on='LTeamID', right_on='TeamID', how='left')\n",
    "df_merged = df_merged.rename(columns={'TeamName':'LTeamName'})\n",
    "df_merged = df_merged.drop(columns=['TeamID_x', 'TeamID_y', 'WTeamID', 'LTeamID'])\n",
    "\n",
    "#Name mapping\n",
    "stat_name = set(team_stats['TEAM'].unique())\n",
    "record_name = set(df_merged['WTeamName'].unique()) | set(df_merged['LTeamName'].unique())\n",
    "mismatch_name = stat_name - record_name\n",
    "name_map = {\n",
    "    'Abilene Christian' : 'Abilene Chr', 'Alabama St.' : 'Alabama St', 'Albany' : 'SUNY Albany', 'American' : 'American Univ', 'Appalachian St.' : 'Appalachian St',\n",
    "    'Arizona St.' : 'Arizona St', 'Arkansas Pine Bluff' : 'Ark Pine Bluff', 'Boise St.' : 'Boise St', 'Boston University' : 'Boston Univ', 'Cal St. Bakersfield' : 'CS Bakersfield',\n",
    "    'Cal St. Fullerton' : 'CS Fullerton', 'Cleveland St.' : 'Cleveland St', 'Coastal Carolina' : 'Coastal Car', 'College of Charleston' : 'Col Charleston', 'Colorado St.' : 'Colorado St',\n",
    "    'East Tennessee St.' : 'ETSU', 'Eastern Kentucky' : 'E Kentucky', 'Eastern Washington' : 'E Washington', 'Fairleigh Dickinson' : 'F Dickinson', 'Florida Atlantic' : 'FL Atlantic', \n",
    "    'Florida Gulf Coast' : 'FGCU', 'Florida St.' : 'Florida St', 'Fresno St.' : 'Fresno St', 'George Washington' : 'G Washington', 'Georgia St.' : 'Georgia St', 'Grambling St.' : 'Grambling',\n",
    "    'Indiana St.' : 'Indiana St', 'Iowa St.' : 'Iowa St', 'Jacksonville St.' : 'Jacksonville St', 'Kansas St.' : 'Kansas St', 'Kennesaw St.' : 'Kennesaw', 'Kent St.' : 'Kent', 'Little Rock' : 'Ark Little Rock',\n",
    "    'Long Beach St.' : 'Long Beach St', 'Louisiana Lafayette' : 'Lafayette', 'Loyola Chicago' : 'Loyola-Chicago', 'McNeese St.' : 'McNeese St', 'Michigan St.' : 'Michigan St',\n",
    "    'Middle Tennessee' : 'MTSU', 'Milwaukee' : 'WI Milwaukee', 'Mississippi St.' : 'Mississippi St', 'Mississippi Valley St.' : 'MS Valley St', 'Montana St.' : 'Montana St', 'Morehead St.' : 'Morehead St',\n",
    "    'Morgan St.' : 'Morgan St', \"Mount St. Mary's\" : \"Mt St Mary's\", 'Murray St.' : 'Murray St', 'Nebraska Omaha' : 'NE Omaha', 'New Mexico St.' : 'New Mexico St', 'Norfolk St.' : 'Norfolk St', \n",
    "    'North Carolina Central' : 'NC Central', 'North Carolina A&T' : 'NC A&T', 'North Carolina St.' : 'NC State', 'Northern Colorado' : 'N colorado', 'Northern Kentucky' : 'N Kentucky',\n",
    "    'Northwestern St.' : 'Northwestern LA', 'Ohio St.' : 'Ohio St', 'Oklahoma St.' : 'Oklahoma St', 'Oregon St.' : 'Oregon St', 'Penn St.' : 'Penn St', 'Prairie View A&M' : 'Prairie View',\n",
    "    'SIU Edwardsville' : 'S Illinois', 'Saint Francis' : 'St Francis PA', \"Saint Joseph's\" : \"St Joseph's PA\", 'Saint Louis' : 'St Louis', \"Saint Mary's\" : \"St Mary's CA\", \n",
    "    \"Saint Peter's\" : \"St Peter's\", 'Sam Houston St.' : 'Sam Houston St', 'San Diego St.' : 'San Diego St', 'South Dakota St.' : 'S Dakota St', 'Southeast Missouri St.' : 'SE Missouri St',\n",
    "    'Southern' : 'Southern Univ', 'St. Bonaventure' : 'St Bonaventure', \"St. John's\" : \"St John's\", 'Stephen F. Austin' : 'SF Austin', 'Texas A&M Corpus Chris' : 'TAM C. Christi',\n",
    "    'Texas Southern' : 'TX Southern', 'UTSA' : 'UT San Antonio', 'Utah St.' : 'Utah St', 'Washington St.' : 'Washington St', 'Weber St.' : 'Weber St', 'Western Kentucky' : 'WKU',\n",
    "    'Western Michigan' : 'W Michigan', 'Wichita St.' : 'Wichita St', 'Wright St.' : 'Wright St'\n",
    "}\n",
    "team_stats['TEAM'] = team_stats['TEAM'].replace(name_map)\n",
    "\n",
    "w_stats = team_stats.rename(columns=lambda col: f'W_{col}' if col not in ['YEAR', 'TEAM'] else col)\n",
    "l_stats = team_stats.rename(columns=lambda col: f'L_{col}' if col not in ['YEAR', 'TEAM'] else col)\n",
    "\n",
    "#Table with individual game and team stats\n",
    "df_merged = df_merged[df_merged['Season'] >= 2010]\n",
    "df_merged = df_merged.merge(w_stats, left_on=['Season', 'WTeamName'], right_on=['YEAR', 'TEAM'], how='left')\n",
    "df_merged = df_merged.merge(l_stats, left_on=['Season', 'LTeamName'], right_on=['YEAR', 'TEAM'], how='left')\n",
    "final_df = df_merged.dropna()\n",
    "final_df = final_df.drop(columns=['YEAR_x', 'TEAM_x', 'YEAR_y', 'TEAM_y'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f002ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df.copy()\n",
    "\n",
    "flip = np.random.rand(len(df)) < 0.5\n",
    "\n",
    "\n",
    "team1_stats = df.filter(regex='^W_').copy()\n",
    "team2_stats = df.filter(regex='^L_').copy()\n",
    "\n",
    "team1_stats.columns = team1_stats.columns.str.replace('^W_', 'team1_', regex=True)\n",
    "team2_stats.columns = team2_stats.columns.str.replace('^L_', 'team2_', regex=True)\n",
    "\n",
    "team1_stats_flipped = df.filter(regex='^L_').copy()\n",
    "team2_stats_flipped = df.filter(regex='^W_').copy()\n",
    "\n",
    "team1_stats_flipped.columns = team1_stats_flipped.columns.str.replace('^L_', 'team1_', regex=True)\n",
    "team2_stats_flipped.columns = team2_stats_flipped.columns.str.replace('^W_', 'team2_', regex=True)\n",
    "\n",
    "team1_stats[flip] = team1_stats_flipped[flip]\n",
    "team2_stats[flip] = team2_stats_flipped[flip]\n",
    "\n",
    "team1_stats.to_csv('team1_stats.csv')\n",
    "team2_stats.to_csv('team2_stats.csv')\n",
    "\n",
    "X = pd.concat([\n",
    "    team1_stats, team2_stats\n",
    " ], axis=1)\n",
    "\n",
    "y = (~flip).astype(int)\n",
    "\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a9177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6703\n",
      "MCC: 0.3405\n",
      "F1 Score: 0.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sweat\\OneDrive\\Desktop\\march_madness_ai\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lr = LogisticRegression(max_iter = 10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "l_train_acc = accuracy_score(y_train, lr.predict(X_train))\n",
    "l_train_mcc = matthews_corrcoef(y_train, lr.predict(X_train))\n",
    "l_train_f1 = f1_score(y_train, lr.predict(X_train))\n",
    "\n",
    "l_test_acc = accuracy_score(y_test, lr.predict(X_test))\n",
    "l_test_mcc = matthews_corrcoef(y_test, lr.predict(X_test))\n",
    "l_test_f1 = f1_score(y_test, lr.predict(X_test))\n",
    "\n",
    "print(f\"Test Accuracy: {l_test_acc:.4f}\")\n",
    "print(f\"MCC: {l_test_mcc:.4f}\")\n",
    "print(f\"F1 Score: {l_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a90b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7135\n",
      "MCC: 0.4270\n",
      "F1 Score: 0.7166\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=1000,      # number of trees, fewer to avoid overfitting small data\n",
    "    max_depth=4,           # control model complexity, smaller depth to prevent overfitting\n",
    "    learning_rate=0.1,     # moderate learning rate\n",
    "    subsample=0.8,         # use 80% of data per tree (helps generalize)\n",
    "    colsample_bytree=0.8,  # use 80% of features per tree (reduces overfitting)\n",
    "    gamma=1,               # minimum loss reduction to make split (regularization)\n",
    "    reg_lambda=1,          # L2 regularization term on weights\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xg = model.fit(X_train, y_train)\n",
    "\n",
    "xg_train_acc = accuracy_score(y_train, xg.predict(X_train))\n",
    "xg_train_mcc = matthews_corrcoef(y_train, xg.predict(X_train))\n",
    "xg_train_f1 = f1_score(y_train, xg.predict(X_train))\n",
    "\n",
    "xg_test_acc = accuracy_score(y_test, xg.predict(X_test))\n",
    "xg_test_mcc = matthews_corrcoef(y_test, xg.predict(X_test))\n",
    "xg_test_f1 = f1_score(y_test, xg.predict(X_test))\n",
    "\n",
    "print(f\"Test Accuracy: {xg_test_acc:.4f}\")\n",
    "print(f\"MCC: {xg_test_mcc:.4f}\")\n",
    "print(f\"F1 Score: {xg_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5fab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7027\n",
      "MCC: 0.4058\n",
      "F1 Score: 0.7120\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "rf = rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_train_acc = accuracy_score(y_train, rf.predict(X_train))\n",
    "rf_train_mcc = matthews_corrcoef(y_train, rf.predict(X_train))\n",
    "rf_train_f1 = f1_score(y_train, rf.predict(X_train))\n",
    "\n",
    "rf_test_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "rf_test_mcc = matthews_corrcoef(y_test, rf.predict(X_test))\n",
    "rf_test_f1 = f1_score(y_test, rf.predict(X_test))\n",
    "\n",
    "print(f\"Accuracy: {rf_test_acc:.4f}\")\n",
    "print(f\"MCC: {rf_test_mcc:.4f}\")\n",
    "print(f\"F1 Score: {rf_test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69889881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 0.7081\n",
      "Stacked Model F1 Score: 0.7065\n",
      "Stacked Model MCC: 0.4164\n"
     ]
    }
   ],
   "source": [
    "lr_train = lr.predict_proba(X_train)[:, 1]\n",
    "rf_train = rf.predict_proba(X_train)[:, 1]\n",
    "xg_train = xg.predict_proba(X_train)[:, 1]\n",
    "\n",
    "stack_X_train = np.column_stack((lr_train, rf_train, xg_train))\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=10000)\n",
    "meta_model.fit(stack_X_train, y_train)\n",
    "\n",
    "\n",
    "lr_test = lr.predict_proba(X_test)[:, 1]\n",
    "rf_test = rf.predict_proba(X_test)[:, 1]\n",
    "xg_test = xg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "stack_X_test = np.column_stack((lr_test, rf_test, xg_test))\n",
    "\n",
    "final_preds = meta_model.predict(stack_X_test)\n",
    "\n",
    "s_test_acc = accuracy_score(y_test, final_preds)\n",
    "s_test_f1 = f1_score(y_test, final_preds)\n",
    "s_test_mcc = matthews_corrcoef(y_test, final_preds)\n",
    "\n",
    "print(f\"Stacked Model Accuracy: {s_test_acc:.4f}\")\n",
    "print(f\"Stacked Model F1 Score: {s_test_f1:.4f}\")\n",
    "print(f\"Stacked Model MCC: {s_test_mcc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab370b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
